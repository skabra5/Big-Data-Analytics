{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDS 561 Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GpLWrLANDrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Xpj7svRKm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RGp8fY-RTZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5a-M1d2_p3r",
        "colab_type": "code",
        "outputId": "77994033-d212-4ed8-bf76-46ad5a500b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Importing the data as a pandas dataframe and printing its shape\n",
        "\n",
        "import pandas as pd\n",
        "amazon_df = pd.read_csv(\"/content/Amazon_Responded_Oct05.csv\") \n",
        "amazon_df.head()\n",
        "amazon_df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(462029, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZFzflqtBjhe",
        "colab_type": "code",
        "outputId": "650812d9-f8e7-4e31-aed2-49ee63c24a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Removing all Null values from the dataframe amazon_df and printing the new dimensions\n",
        "\n",
        "amazon_clean = amazon_df.dropna(how=\"all\")\n",
        "amazon_clean.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(378134, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNau3JEZnFrG",
        "colab_type": "code",
        "outputId": "9e202770-cbf3-4279-8beb-6ed373ac13fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "#Splitting the tweet_created_at column using \"Space\" as a delimiter to get the month and date\n",
        "DateField = amazon_clean[\"tweet_created_at\"].str.split(\" \", n = 6, expand = True) \n",
        "  \n",
        "amazon_clean[\"WeekDay\"]= DateField[0] \n",
        "amazon_clean[\"Month\"]= DateField[1] \n",
        "amazon_clean[\"Date\"]= DateField[2] \n",
        "amazon_clean[\"TimeStamp\"]= DateField[3] \n",
        "amazon_clean[\"Geo\"]= DateField[4] \n",
        "amazon_clean[\"Year\"]= DateField[5] \n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmYDSSGYq8N9",
        "colab_type": "code",
        "outputId": "cba1db03-1c67-46f6-efab-ac1d571de533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "#Creating Create_Date column by joining the columns \"Month\" and \"Date\" in 'mmm dd' format\n",
        "\n",
        "amazon_clean['Create_Date'] = amazon_clean[['Month', 'Date']].apply(lambda x: ' '.join(x), axis=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWnXCi1gpfMt",
        "colab_type": "code",
        "outputId": "682ac30a-2417-4819-c4e7-9e56d1a4e3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "# Printing amazon_clean to check the new column \"Create_Date\"\n",
        "amazon_clean.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_str</th>\n",
              "      <th>tweet_created_at</th>\n",
              "      <th>user_screen_name</th>\n",
              "      <th>user_id_str</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>user_favourites_count</th>\n",
              "      <th>user_protected</th>\n",
              "      <th>user_listed_count</th>\n",
              "      <th>user_following</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>user_created_at</th>\n",
              "      <th>tweet_language</th>\n",
              "      <th>text_</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>favorited</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>in_reply_to_status_id_str</th>\n",
              "      <th>in_reply_to_user_id_str</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>text</th>\n",
              "      <th>WeekDay</th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>TimeStamp</th>\n",
              "      <th>Geo</th>\n",
              "      <th>Year</th>\n",
              "      <th>Create_Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'793270689780203520'</td>\n",
              "      <td>Tue Nov 01 01:57:25 +0000 2016</td>\n",
              "      <td>SeanEPanjab</td>\n",
              "      <td>143515471.0</td>\n",
              "      <td>51287.0</td>\n",
              "      <td>4079.0</td>\n",
              "      <td>False</td>\n",
              "      <td>74.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Content marketer; Polyglot; Beard aficionado; ...</td>\n",
              "      <td>غریب الوطن</td>\n",
              "      <td>False</td>\n",
              "      <td>1503.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>Thu May 13 17:43:52 +0000 2010</td>\n",
              "      <td>en</td>\n",
              "      <td>@AmazonHelp Can you please DM me? A product I ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>AmazonHelp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85741735.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Nov</td>\n",
              "      <td>01</td>\n",
              "      <td>01:57:25</td>\n",
              "      <td>+0000</td>\n",
              "      <td>2016</td>\n",
              "      <td>Nov 01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'793281386912354304'</td>\n",
              "      <td>Tue Nov 01 02:39:55 +0000 2016</td>\n",
              "      <td>AmazonHelp</td>\n",
              "      <td>85741735.0</td>\n",
              "      <td>2225450.0</td>\n",
              "      <td>11366.0</td>\n",
              "      <td>False</td>\n",
              "      <td>796.0</td>\n",
              "      <td>False</td>\n",
              "      <td>We answer Amazon support questions 7 days a we...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>149569.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>Wed Oct 28 04:17:54 +0000 2009</td>\n",
              "      <td>en</td>\n",
              "      <td>@SeanEPanjab I'm sorry, we're unable to DM you...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>SeanEPanjab</td>\n",
              "      <td>7.930000e+17</td>\n",
              "      <td>143515471.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Nov</td>\n",
              "      <td>01</td>\n",
              "      <td>02:39:55</td>\n",
              "      <td>+0000</td>\n",
              "      <td>2016</td>\n",
              "      <td>Nov 01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'793501578766319616'</td>\n",
              "      <td>Tue Nov 01 17:14:53 +0000 2016</td>\n",
              "      <td>SeanEPanjab</td>\n",
              "      <td>143515471.0</td>\n",
              "      <td>51287.0</td>\n",
              "      <td>4079.0</td>\n",
              "      <td>False</td>\n",
              "      <td>74.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Content marketer; Polyglot; Beard aficionado; ...</td>\n",
              "      <td>غریب الوطن</td>\n",
              "      <td>False</td>\n",
              "      <td>1503.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>Thu May 13 17:43:52 +0000 2010</td>\n",
              "      <td>en</td>\n",
              "      <td>@AmazonHelp It was purchased on https://t.co/g...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>AmazonHelp</td>\n",
              "      <td>7.930000e+17</td>\n",
              "      <td>85741735.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>@AmazonHelp It was purchased on https://t.co/g...</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Nov</td>\n",
              "      <td>01</td>\n",
              "      <td>17:14:53</td>\n",
              "      <td>+0000</td>\n",
              "      <td>2016</td>\n",
              "      <td>Nov 01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'793501657346682880'</td>\n",
              "      <td>Tue Nov 01 17:15:12 +0000 2016</td>\n",
              "      <td>SeanEPanjab</td>\n",
              "      <td>143515471.0</td>\n",
              "      <td>51287.0</td>\n",
              "      <td>4079.0</td>\n",
              "      <td>False</td>\n",
              "      <td>74.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Content marketer; Polyglot; Beard aficionado; ...</td>\n",
              "      <td>غریب الوطن</td>\n",
              "      <td>False</td>\n",
              "      <td>1503.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>Thu May 13 17:43:52 +0000 2010</td>\n",
              "      <td>en</td>\n",
              "      <td>@AmazonHelp I am following you now, if it help...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>AmazonHelp</td>\n",
              "      <td>7.930000e+17</td>\n",
              "      <td>85741735.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Nov</td>\n",
              "      <td>01</td>\n",
              "      <td>17:15:12</td>\n",
              "      <td>+0000</td>\n",
              "      <td>2016</td>\n",
              "      <td>Nov 01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>'793502854459879424'</td>\n",
              "      <td>Tue Nov 01 17:19:57 +0000 2016</td>\n",
              "      <td>AmazonHelp</td>\n",
              "      <td>85741735.0</td>\n",
              "      <td>2225450.0</td>\n",
              "      <td>11366.0</td>\n",
              "      <td>False</td>\n",
              "      <td>796.0</td>\n",
              "      <td>False</td>\n",
              "      <td>We answer Amazon support questions 7 days a we...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>149569.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>Wed Oct 28 04:17:54 +0000 2009</td>\n",
              "      <td>en</td>\n",
              "      <td>@SeanEPanjab Please give us a call/chat so we ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>SeanEPanjab</td>\n",
              "      <td>7.940000e+17</td>\n",
              "      <td>143515471.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>@SeanEPanjab Please give us a call/chat so we ...</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Nov</td>\n",
              "      <td>01</td>\n",
              "      <td>17:19:57</td>\n",
              "      <td>+0000</td>\n",
              "      <td>2016</td>\n",
              "      <td>Nov 01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id_str                tweet_created_at  ...  Year  Create_Date\n",
              "1  '793270689780203520'  Tue Nov 01 01:57:25 +0000 2016  ...  2016       Nov 01\n",
              "2  '793281386912354304'  Tue Nov 01 02:39:55 +0000 2016  ...  2016       Nov 01\n",
              "3  '793501578766319616'  Tue Nov 01 17:14:53 +0000 2016  ...  2016       Nov 01\n",
              "4  '793501657346682880'  Tue Nov 01 17:15:12 +0000 2016  ...  2016       Nov 01\n",
              "5  '793502854459879424'  Tue Nov 01 17:19:57 +0000 2016  ...  2016       Nov 01\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FML3NutgEGS9",
        "colab_type": "code",
        "outputId": "c39053e3-03ec-49ce-aea4-bd8d60dd8123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Converting Pandas Dataframe \"amazon_clean\" into Spark Dataframe \"Tweet_sdf\" and printing the first 10 rows\n",
        "\n",
        "amazon_clean = amazon_clean.astype(str) # Converting pandas df to string first\n",
        "Tweet_sdf = spark.createDataFrame(amazon_clean)\n",
        "Tweet_sdf.show(10, False) # False allows us to show entire content of the columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------------------------------+----------------+-----------+-------------------+---------------------+--------------+-----------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------+-------------+-------------+--------------------+------------------+------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+-----------------------+-------------------------+-----------------------+-------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------+-------+-----+----+---------+-----+----+-----------+\n",
            "|id_str              |tweet_created_at              |user_screen_name|user_id_str|user_statuses_count|user_favourites_count|user_protected|user_listed_count|user_following|user_description                                                                                                                              |user_location|user_verified|user_followers_count|user_friends_count|user_created_at               |tweet_language|text_                                                                                                                                     |favorite_count|favorited|in_reply_to_screen_name|in_reply_to_status_id_str|in_reply_to_user_id_str|retweet_count|retweeted|text                                                                                                                                     |WeekDay|Month|Date|TimeStamp|Geo  |Year|Create_Date|\n",
            "+--------------------+------------------------------+----------------+-----------+-------------------+---------------------+--------------+-----------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------+-------------+-------------+--------------------+------------------+------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+-----------------------+-------------------------+-----------------------+-------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------+-------+-----+----+---------+-----+----+-----------+\n",
            "|'793270689780203520'|Tue Nov 01 01:57:25 +0000 2016|SeanEPanjab     |143515471.0|51287.0            |4079.0               |False         |74.0             |False         |Content marketer; Polyglot; Beard aficionado; Sikh. Persian, Catalan, French, Spanish. You'll find lol in the interstitial lulls of my tweets.|غریب الوطن   |False        |1503.0              |850.0             |Thu May 13 17:43:52 +0000 2010|en            |@AmazonHelp Can you please DM me? A product I ordered last year never arrived.                                                            |0.0           |False    |AmazonHelp             |nan                      |85741735.0             |0.0          |False    |nan                                                                                                                                      |Tue    |Nov  |01  |01:57:25 |+0000|2016|Nov 01     |\n",
            "|'793281386912354304'|Tue Nov 01 02:39:55 +0000 2016|AmazonHelp      |85741735.0 |2225450.0          |11366.0              |False         |796.0            |False         |We answer Amazon support questions 7 days a week. Support available in English / Deutsch / Español / Português / Français / Italiano / 日本語 |nan          |True         |149569.0            |53.0              |Wed Oct 28 04:17:54 +0000 2009|en            |@SeanEPanjab I'm sorry, we're unable to DM you. Was this order purchased on https://t.co/nUUp5MLhYl, or one of our other sites? ^CL       |0.0           |False    |SeanEPanjab            |7.93e+17                 |143515471.0            |0.0          |False    |nan                                                                                                                                      |Tue    |Nov  |01  |02:39:55 |+0000|2016|Nov 01     |\n",
            "|'793501578766319616'|Tue Nov 01 17:14:53 +0000 2016|SeanEPanjab     |143515471.0|51287.0            |4079.0               |False         |74.0             |False         |Content marketer; Polyglot; Beard aficionado; Sikh. Persian, Catalan, French, Spanish. You'll find lol in the interstitial lulls of my tweets.|غریب الوطن   |False        |1503.0              |850.0             |Thu May 13 17:43:52 +0000 2010|en            |@AmazonHelp It was purchased on https://t.co/gPWnuSkbwC.                                                                                  |0.0           |False    |AmazonHelp             |7.93e+17                 |85741735.0             |0.0          |False    |@AmazonHelp It was purchased on https://t.co/gPWnuSkbwC.                                                                                 |Tue    |Nov  |01  |17:14:53 |+0000|2016|Nov 01     |\n",
            "|'793501657346682880'|Tue Nov 01 17:15:12 +0000 2016|SeanEPanjab     |143515471.0|51287.0            |4079.0               |False         |74.0             |False         |Content marketer; Polyglot; Beard aficionado; Sikh. Persian, Catalan, French, Spanish. You'll find lol in the interstitial lulls of my tweets.|غریب الوطن   |False        |1503.0              |850.0             |Thu May 13 17:43:52 +0000 2010|en            |@AmazonHelp I am following you now, if it helps to DM.                                                                                    |0.0           |False    |AmazonHelp             |7.93e+17                 |85741735.0             |0.0          |False    |nan                                                                                                                                      |Tue    |Nov  |01  |17:15:12 |+0000|2016|Nov 01     |\n",
            "|'793502854459879424'|Tue Nov 01 17:19:57 +0000 2016|AmazonHelp      |85741735.0 |2225450.0          |11366.0              |False         |796.0            |False         |We answer Amazon support questions 7 days a week. Support available in English / Deutsch / Español / Português / Français / Italiano / 日本語 |nan          |True         |149569.0            |53.0              |Wed Oct 28 04:17:54 +0000 2009|en            |@SeanEPanjab Please give us a call/chat so we can look into this order for you: https://t.co/hApLpMlfHN. ^HB                              |0.0           |False    |SeanEPanjab            |7.94e+17                 |143515471.0            |0.0          |False    |@SeanEPanjab Please give us a call/chat so we can look into this order for you: https://t.co/hApLpMlfHN. ^HB                             |Tue    |Nov  |01  |17:19:57 |+0000|2016|Nov 01     |\n",
            "|'793504235400884224'|Tue Nov 01 17:25:26 +0000 2016|AmazonHelp      |85741735.0 |2225450.0          |11366.0              |False         |796.0            |False         |We answer Amazon support questions 7 days a week. Support available in English / Deutsch / Español / Português / Français / Italiano / 日本語 |nan          |True         |149569.0            |53.0              |Wed Oct 28 04:17:54 +0000 2009|en            |@SeanEPanjab Without providing any sensitive information, do the order details indicate that the item was ever shipped? ^SW               |0.0           |False    |SeanEPanjab            |7.94e+17                 |143515471.0            |0.0          |False    |nan                                                                                                                                      |Tue    |Nov  |01  |17:25:26 |+0000|2016|Nov 01     |\n",
            "|'793511847899070465'|Tue Nov 01 17:55:41 +0000 2016|SeanEPanjab     |143515471.0|51287.0            |4079.0               |False         |74.0             |False         |Content marketer; Polyglot; Beard aficionado; Sikh. Persian, Catalan, French, Spanish. You'll find lol in the interstitial lulls of my tweets.|غریب الوطن   |False        |1503.0              |850.0             |Thu May 13 17:43:52 +0000 2010|en            |@AmazonHelp It was shipped and possibly delivered to my old place of employment. But when I asked for it, no one had it. And so I wonder +|0.0           |False    |AmazonHelp             |7.94e+17                 |85741735.0             |0.0          |False    |nan                                                                                                                                      |Tue    |Nov  |01  |17:55:41 |+0000|2016|Nov 01     |\n",
            "|'793511899279208449'|Tue Nov 01 17:55:54 +0000 2016|SeanEPanjab     |143515471.0|51287.0            |4079.0               |False         |74.0             |False         |Content marketer; Polyglot; Beard aficionado; Sikh. Persian, Catalan, French, Spanish. You'll find lol in the interstitial lulls of my tweets.|غریب الوطن   |False        |1503.0              |850.0             |Thu May 13 17:43:52 +0000 2010|en            |@AmazonHelp if it was lost. I have the order #.                                                                                           |0.0           |False    |AmazonHelp             |7.94e+17                 |85741735.0             |0.0          |False    |nan                                                                                                                                      |Tue    |Nov  |01  |17:55:54 |+0000|2016|Nov 01     |\n",
            "|'793513446633533440'|Tue Nov 01 18:02:03 +0000 2016|AmazonHelp      |85741735.0 |2225450.0          |11366.0              |False         |796.0            |False         |We answer Amazon support questions 7 days a week. Support available in English / Deutsch / Español / Português / Français / Italiano / 日本語 |nan          |True         |149569.0            |53.0              |Wed Oct 28 04:17:54 +0000 2009|en            |@SeanEPanjab I'm not able to access account info here. Please reach out by Phone/Chat so we can look at this: https://t.co/EKXRLsnxJu ^GL |0.0           |False    |SeanEPanjab            |7.94e+17                 |143515471.0            |0.0          |False    |@SeanEPanjab I'm not able to access account info here. Please reach out by Phone/Chat so we can look at this: https://t.co/EKXRLsnxJu ^GL|Tue    |Nov  |01  |18:02:03 |+0000|2016|Nov 01     |\n",
            "|'793299404975247360'|Tue Nov 01 03:51:31 +0000 2016|aakashwangnoo   |71457972.0 |592.0              |471.0                |False         |11.0             |False         |Don't try to be GOD in your lives...Let HIM work in your lives...and see the magic that he weaves...                                          |New Delhi    |False        |234.0               |57.0              |Fri Sep 04 04:55:01 +0000 2009|en            |@JeffBezos @amazonIN @AmazonHelp Tring...Tring...Tring Who's There? Your Suffering Customers from India Mr. Bezos...Get Up and Help!      |0.0           |False    |JeffBezos              |nan                      |15506669.0             |0.0          |False    |nan                                                                                                                                      |Tue    |Nov  |01  |03:51:31 |+0000|2016|Nov 01     |\n",
            "+--------------------+------------------------------+----------------+-----------+-------------------+---------------------+--------------+-----------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------+-------------+-------------+--------------------+------------------+------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+-----------------------+-------------------------+-----------------------+-------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------+-------+-----+----+---------+-----+----+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2cGLJzkxEbs",
        "colab_type": "code",
        "outputId": "e599039c-e4bc-400e-931c-b2e56a216dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Checking the datatype of our Spark dataframe file Tweet_sdf\n",
        "print(type(Tweet_sdf))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goiJJo-Lxdeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "68266c8c-33e8-4228-83f2-f927f4cdc6fd"
      },
      "source": [
        "# Checking the datatypes of each variable in Tweet_sdf\n",
        "Tweet_sdf.printSchema()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id_str: string (nullable = true)\n",
            " |-- tweet_created_at: string (nullable = true)\n",
            " |-- user_screen_name: string (nullable = true)\n",
            " |-- user_id_str: string (nullable = true)\n",
            " |-- user_statuses_count: string (nullable = true)\n",
            " |-- user_favourites_count: string (nullable = true)\n",
            " |-- user_protected: string (nullable = true)\n",
            " |-- user_listed_count: string (nullable = true)\n",
            " |-- user_following: string (nullable = true)\n",
            " |-- user_description: string (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- user_verified: string (nullable = true)\n",
            " |-- user_followers_count: string (nullable = true)\n",
            " |-- user_friends_count: string (nullable = true)\n",
            " |-- user_created_at: string (nullable = true)\n",
            " |-- tweet_language: string (nullable = true)\n",
            " |-- text_: string (nullable = true)\n",
            " |-- favorite_count: string (nullable = true)\n",
            " |-- favorited: string (nullable = true)\n",
            " |-- in_reply_to_screen_name: string (nullable = true)\n",
            " |-- in_reply_to_status_id_str: string (nullable = true)\n",
            " |-- in_reply_to_user_id_str: string (nullable = true)\n",
            " |-- retweet_count: string (nullable = true)\n",
            " |-- retweeted: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- WeekDay: string (nullable = true)\n",
            " |-- Month: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- TimeStamp: string (nullable = true)\n",
            " |-- Geo: string (nullable = true)\n",
            " |-- Year: string (nullable = true)\n",
            " |-- Create_Date: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHitRXAtIxtH",
        "colab_type": "code",
        "outputId": "253798b1-0e3a-4409-b748-d7601f61e68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "# Extracting columns 'id_str', 'tweet_created_at', 'user_verified', favourite_count', 'retweet_count' and 'text_' for our analysis and printing 20 rows\n",
        "TweetDataCol = Tweet_sdf.select(Tweet_sdf.id_str, Tweet_sdf.Create_Date, Tweet_sdf.user_verified, Tweet_sdf.favorite_count, Tweet_sdf.retweet_count, Tweet_sdf.text_)\n",
        "TweetDataCol.show(20, False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+-------------+--------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|id_str              |Create_Date|user_verified|favorite_count|retweet_count|text_                                                                                                                                                        |\n",
            "+--------------------+-----------+-------------+--------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|'793270689780203520'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp Can you please DM me? A product I ordered last year never arrived.                                                                               |\n",
            "|'793281386912354304'|Nov 01     |True         |0.0           |0.0          |@SeanEPanjab I'm sorry, we're unable to DM you. Was this order purchased on https://t.co/nUUp5MLhYl, or one of our other sites? ^CL                          |\n",
            "|'793501578766319616'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp It was purchased on https://t.co/gPWnuSkbwC.                                                                                                     |\n",
            "|'793501657346682880'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp I am following you now, if it helps to DM.                                                                                                       |\n",
            "|'793502854459879424'|Nov 01     |True         |0.0           |0.0          |@SeanEPanjab Please give us a call/chat so we can look into this order for you: https://t.co/hApLpMlfHN. ^HB                                                 |\n",
            "|'793504235400884224'|Nov 01     |True         |0.0           |0.0          |@SeanEPanjab Without providing any sensitive information, do the order details indicate that the item was ever shipped? ^SW                                  |\n",
            "|'793511847899070465'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp It was shipped and possibly delivered to my old place of employment. But when I asked for it, no one had it. And so I wonder +                   |\n",
            "|'793511899279208449'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp if it was lost. I have the order #.                                                                                                              |\n",
            "|'793513446633533440'|Nov 01     |True         |0.0           |0.0          |@SeanEPanjab I'm not able to access account info here. Please reach out by Phone/Chat so we can look at this: https://t.co/EKXRLsnxJu ^GL                    |\n",
            "|'793299404975247360'|Nov 01     |False        |0.0           |0.0          |@JeffBezos @amazonIN @AmazonHelp Tring...Tring...Tring Who's There? Your Suffering Customers from India Mr. Bezos...Get Up and Help!                         |\n",
            "|'793301295255945216'|Nov 01     |True         |0.0           |0.0          |@aakashwangnoo Hi there, kindly write back to us with the details requested so we can proceed further with this.  ^KJ                                        |\n",
            "|'793407430344310785'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp How many times do you want to write back to you guys??? Check the complaints through email regarding  Order 171-1338898-5999507.                 |\n",
            "|'793423313674571776'|Nov 01     |True         |0.0           |0.0          |@aakashwangnoo Hi! We have responded to you here: https://t.co/v4YVCa3rff ^SG(1/2)                                                                           |\n",
            "|'793423314333134850'|Nov 01     |True         |0.0           |0.0          |@aakashwangnoo Please don’t provide your order details as we consider them to be personal info. Our page is visible to public. ^SG(2/2)                      |\n",
            "|'793467086869630977'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp @amazonIN I am providing my order details as even after providing that ur CC Team is repeatedly shooting me cut copy paste email                 |\n",
            "|'793492430666498050'|Nov 01     |True         |0.0           |0.0          |@aakashwangnoo Hi, I believe we have already got back to you on this. Kindly check for the correspondence here: https://t.co/NTkrxpsbHJ ^AB                  |\n",
            "|'793535036213501952'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp @amazonIN @JeffBezos @consumeraction @ConsumerAffairs @ConsumersUnion You want to silent my voice and call that as Answers to me                 |\n",
            "|'793535221329113088'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp @amazonIN @JeffBezos @consumeraction @ConsumerAffairs @ConsumersUnion SHAME on you Team Amazon India...SHAME SHAME SHAME!!!                      |\n",
            "|'793537840533471232'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp @amazonIN @JeffBezos @consumeraction @ConsumerAffairs @ConsumersUnion Please see attachments. These are Amazon responses. https://t.co/W9FcqQVtCC|\n",
            "|'793538125884645376'|Nov 01     |False        |0.0           |0.0          |@AmazonHelp @amazonIN @JeffBezos @consumeraction @ConsumerAffairs @ConsumersUnion and these are my responses. https://t.co/vTwhtX5oBt                        |\n",
            "+--------------------+-----------+-------------+--------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpCgLN7rQDEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1\n",
        "# Step 1: Remove the records where “user_verified” is “FALSE”.\n",
        "# Using Filter function to remove the rows with “user_verified” as “FALSE”\n",
        "\n",
        "TweetDatafilter = TweetDataCol.rdd.filter(lambda TweetDataCol:'True' in  TweetDataCol[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXCILoxU1LZr",
        "colab_type": "code",
        "outputId": "928b85ee-9156-4ceb-a954-c2d072f59976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Task 1 # Step 1\n",
        "# Printing 5 rows of TweetDatafilter to check the filter\n",
        "TweetDatafilter.take(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id_str=\"'793281386912354304'\", Create_Date='Nov 01', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_=\"@SeanEPanjab I'm sorry, we're unable to DM you. Was this order purchased on https://t.co/nUUp5MLhYl, or one of our other sites? ^CL\"),\n",
              " Row(id_str=\"'793502854459879424'\", Create_Date='Nov 01', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_='@SeanEPanjab Please give us a call/chat so we can look into this order for you: https://t.co/hApLpMlfHN. ^HB'),\n",
              " Row(id_str=\"'793504235400884224'\", Create_Date='Nov 01', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_='@SeanEPanjab Without providing any sensitive information, do the order details indicate that the item was ever shipped? ^SW'),\n",
              " Row(id_str=\"'793513446633533440'\", Create_Date='Nov 01', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_=\"@SeanEPanjab I'm not able to access account info here. Please reach out by Phone/Chat so we can look at this: https://t.co/EKXRLsnxJu ^GL\"),\n",
              " Row(id_str=\"'793301295255945216'\", Create_Date='Nov 01', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_='@aakashwangnoo Hi there, kindly write back to us with the details requested so we can proceed further with this.  ^KJ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBApFU8j7giV",
        "colab_type": "code",
        "outputId": "fee41455-0f59-4aab-ae72-3ec424d07b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Task 1 # Step 1\n",
        "# Obtaining the number of rows from the filtered dataset TweetDatafilter\n",
        "\n",
        "TweetDatafilter.count()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "171899"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OqeM2Xn9CU_",
        "colab_type": "code",
        "outputId": "fdd13d9f-427f-4dbf-dba4-63c110a24c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Converting the resultant pipelined RDD to Spark Dataframe \n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "#sc = SparkContext()\n",
        "#tweets = spark.sparkContext.parallelize(TweetDatafilter.collect())\n",
        "TweetDatafilter = TweetDatafilter.toDF()\n",
        "type(TweetDatafilter)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1psUZK233X0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1 \n",
        "# Step 2: For the remaining records (“user_verified” is “TRUE”), group by Create_date, and count the number of tweets for each Create_Date.\n",
        "\n",
        "import pyspark.sql.functions as f\n",
        "groupeByDate = TweetDatafilter.groupby('Create_Date').count().withColumnRenamed(\"count\",\"tweet_count\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYhd7X5X5BzZ",
        "colab_type": "code",
        "outputId": "02def013-65ef-428e-c875-265942469643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Task 1 # Step 2\n",
        "# Sorting the result of groupby operation to arrange in ascending order and showing the first 100 rows\n",
        "# We obtain the highest number of tweets for the date \"Jan 03\" and the number of tweets are 1536\n",
        "\n",
        "groupeByDate.sort((groupeByDate.tweet_count).desc()).show(100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+-----------+\n",
            "|Create_Date|tweet_count|\n",
            "+-----------+-----------+\n",
            "|     Jan 03|       1536|\n",
            "|     Jan 10|       1508|\n",
            "|     Jan 11|       1496|\n",
            "|     Jan 12|       1410|\n",
            "|     Jan 06|       1364|\n",
            "|     Jan 07|       1360|\n",
            "|     Jan 20|       1342|\n",
            "|     Mar 02|       1298|\n",
            "|     Jan 13|       1295|\n",
            "|     Jan 21|       1292|\n",
            "|     Jan 14|       1290|\n",
            "|     Jan 18|       1286|\n",
            "|     Dec 15|       1279|\n",
            "|     Jan 24|       1259|\n",
            "|     Nov 18|       1249|\n",
            "|     Dec 03|       1201|\n",
            "|     Jan 02|       1196|\n",
            "|     Jun 27|       1192|\n",
            "|     Jul 04|       1190|\n",
            "|     Jan 19|       1175|\n",
            "|     Jan 25|       1163|\n",
            "|     Jan 23|       1149|\n",
            "|     Jan 08|       1143|\n",
            "|     Jan 17|       1124|\n",
            "|     May 11|       1120|\n",
            "|     Jul 03|       1112|\n",
            "|     Mar 30|       1109|\n",
            "|     Apr 05|       1089|\n",
            "|     Jan 26|       1083|\n",
            "|     Jan 27|       1080|\n",
            "|     Jun 20|       1074|\n",
            "|     Jan 04|       1071|\n",
            "|     Feb 22|       1058|\n",
            "|     Nov 05|       1058|\n",
            "|     Feb 09|       1054|\n",
            "|     Jun 23|       1045|\n",
            "|     Jun 30|       1040|\n",
            "|     Jan 22|       1024|\n",
            "|     May 03|       1020|\n",
            "|     Mar 08|       1019|\n",
            "|     Jul 29|       1019|\n",
            "|     Mar 29|       1018|\n",
            "|     Apr 18|       1016|\n",
            "|     Jan 16|       1007|\n",
            "|     Jan 15|       1006|\n",
            "|     Jun 07|       1004|\n",
            "|     Jan 09|       1003|\n",
            "|     Feb 02|        987|\n",
            "|     Jun 02|        982|\n",
            "|     Dec 10|        979|\n",
            "|     Dec 13|        979|\n",
            "|     Dec 26|        978|\n",
            "|     Jan 30|        968|\n",
            "|     Feb 28|        968|\n",
            "|     Feb 03|        960|\n",
            "|     Jan 28|        956|\n",
            "|     Apr 21|        955|\n",
            "|     Jun 28|        955|\n",
            "|     Feb 14|        953|\n",
            "|     Nov 29|        952|\n",
            "|     Feb 23|        940|\n",
            "|     Feb 08|        926|\n",
            "|     Jul 05|        925|\n",
            "|     Feb 16|        924|\n",
            "|     Mar 31|        921|\n",
            "|     Feb 13|        921|\n",
            "|     Feb 15|        920|\n",
            "|     Dec 11|        918|\n",
            "|     Jan 31|        914|\n",
            "|     Nov 23|        907|\n",
            "|     Mar 09|        906|\n",
            "|     Feb 01|        902|\n",
            "|     Feb 21|        898|\n",
            "|     Dec 04|        884|\n",
            "|     Feb 10|        880|\n",
            "|     Apr 14|        878|\n",
            "|     Nov 02|        878|\n",
            "|     Feb 27|        876|\n",
            "|     Dec 01|        875|\n",
            "|     Feb 07|        875|\n",
            "|     Apr 01|        872|\n",
            "|     Feb 04|        869|\n",
            "|     Feb 11|        868|\n",
            "|     Jul 16|        864|\n",
            "|     Apr 10|        863|\n",
            "|     May 24|        843|\n",
            "|     Feb 24|        835|\n",
            "|     Dec 31|        835|\n",
            "|     Dec 05|        824|\n",
            "|     Dec 21|        819|\n",
            "|     Jul 19|        817|\n",
            "|     May 29|        816|\n",
            "|     Feb 06|        814|\n",
            "|     May 19|        802|\n",
            "|     Jun 25|        801|\n",
            "|     May 13|        798|\n",
            "|     Jun 13|        792|\n",
            "|     Nov 20|        789|\n",
            "|     Feb 25|        786|\n",
            "|     Jul 11|        783|\n",
            "+-----------+-----------+\n",
            "only showing top 100 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xPTiqmCjFsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Filter the records with the date of highest number of tweets, i.e., Jan 03\n",
        "\n",
        "Step3Data = TweetDatafilter\n",
        "Step3Data = Step3Data.rdd.filter(lambda Step3Data:'Jan 03' in  Step3Data[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeT06xEXjF4_",
        "colab_type": "code",
        "outputId": "7c7c3cdb-4085-40b4-f998-1e1225af9e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Displaying first 5 records\n",
        "Step3Data.take(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id_str=\"'816139627270721537'\", Create_Date='Jan 03', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_=\"@mcp111 Hey! We'll have this looked into internally. Thanks for your patience. ^HK\"),\n",
              " Row(id_str=\"'816357712732819467'\", Create_Date='Jan 03', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_=\"@mcp111 Hi there, you can change the country from the settings. Please reach us via the link provided earlier and we'll help you out, ^VM\"),\n",
              " Row(id_str=\"'816167583263162369'\", Create_Date='Jan 03', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_=\"@stevebrowne Hi Steve, sorry to hear this. As we can't view accounts here, please contact here for more options: https://t.co/JzP7hlA23B ^CJ\"),\n",
              " Row(id_str=\"'816326113660174336'\", Create_Date='Jan 03', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_=\"@boozysmurf We'd like the chance to look into this w/ you &amp; investigate further. Pls reach out by phone/chat: https://t.co/3pBuw1SV0L ^KD\"),\n",
              " Row(id_str=\"'816359349358575616'\", Create_Date='Jan 03', user_verified='True', favorite_count='0.0', retweet_count='0.0', text_='@MeghanSuslak If you have the tracking ID from the shipping label, please contact us by phone or chat here: https://t.co/CYqkdUakWJ ^GL')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yHOMLjIjGFu",
        "colab_type": "code",
        "outputId": "9e1195d0-5082-488c-8390-451a90421ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Converting Step3Data to Spark dataframe\n",
        "Step3Data = Step3Data.toDF()\n",
        "type(Step3Data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB-tmWgpvAlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Converting columns user_favourites_count and retweet_count from string data type to integer data type\n",
        "\n",
        "from pyspark.sql.types import IntegerType\n",
        "Step3Data = Step3Data.withColumn(\"favorite_count\", Step3Data[\"favorite_count\"].cast(IntegerType()))\n",
        "Step3Data = Step3Data.withColumn(\"retweet_count\", Step3Data[\"retweet_count\"].cast(IntegerType()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0jUwnE-5CYh",
        "colab_type": "code",
        "outputId": "35b41116-fabb-4faa-b98c-f7393333684c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# Checking the datatypes of columns\n",
        "Step3Data.printSchema()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id_str: string (nullable = true)\n",
            " |-- Create_Date: string (nullable = true)\n",
            " |-- user_verified: string (nullable = true)\n",
            " |-- favorite_count: integer (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- text_: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zquNlwFZ5Cb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Calculating the sum of favourite counts and retweet counts for each tweet from Jan 03\n",
        "\n",
        "Step3Data = Step3Data.withColumn('Sum_favourites_retweets', Step3Data.favorite_count + Step3Data.retweet_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBhWpPpj5CgZ",
        "colab_type": "code",
        "outputId": "587cbe43-7fe6-4b59-d311-ea4025de739f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Checking the result by printing 5 rows\n",
        "Step3Data.take(5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id_str=\"'816139627270721537'\", Create_Date='Jan 03', user_verified='True', favorite_count=0, retweet_count=0, text_=\"@mcp111 Hey! We'll have this looked into internally. Thanks for your patience. ^HK\", Sum_favourites_retweets=0),\n",
              " Row(id_str=\"'816357712732819467'\", Create_Date='Jan 03', user_verified='True', favorite_count=0, retweet_count=0, text_=\"@mcp111 Hi there, you can change the country from the settings. Please reach us via the link provided earlier and we'll help you out, ^VM\", Sum_favourites_retweets=0),\n",
              " Row(id_str=\"'816167583263162369'\", Create_Date='Jan 03', user_verified='True', favorite_count=0, retweet_count=0, text_=\"@stevebrowne Hi Steve, sorry to hear this. As we can't view accounts here, please contact here for more options: https://t.co/JzP7hlA23B ^CJ\", Sum_favourites_retweets=0),\n",
              " Row(id_str=\"'816326113660174336'\", Create_Date='Jan 03', user_verified='True', favorite_count=0, retweet_count=0, text_=\"@boozysmurf We'd like the chance to look into this w/ you &amp; investigate further. Pls reach out by phone/chat: https://t.co/3pBuw1SV0L ^KD\", Sum_favourites_retweets=0),\n",
              " Row(id_str=\"'816359349358575616'\", Create_Date='Jan 03', user_verified='True', favorite_count=0, retweet_count=0, text_='@MeghanSuslak If you have the tracking ID from the shipping label, please contact us by phone or chat here: https://t.co/CYqkdUakWJ ^GL', Sum_favourites_retweets=0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnixhCyI3Pjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Selecting top 100 tweets with highest sum of favourite_count + retweet_count\n",
        "\n",
        "from pyspark.sql.functions import desc \n",
        "Step3DataTop100 = Step3Data.sort(desc(\"Sum_favourites_retweets\")).limit(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlodIiVcxMwU",
        "colab_type": "code",
        "outputId": "9788b11b-2243-41d3-f64c-607f0d3c1fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Checking the result by printing first 20 rows\n",
        "Step3DataTop100.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+-------------+--------------+-------------+--------------------+-----------------------+\n",
            "|              id_str|Create_Date|user_verified|favorite_count|retweet_count|               text_|Sum_favourites_retweets|\n",
            "+--------------------+-----------+-------------+--------------+-------------+--------------------+-----------------------+\n",
            "|'816329761530093568'|     Jan 03|         True|             4|            1|@amazon worst sho...|                      5|\n",
            "|'816083406962434048'|     Jan 03|         True|             2|            1|@ItsJosshA We alw...|                      3|\n",
            "|'816086117938319360'|     Jan 03|         True|             2|            0|@ItsJosshA Oh no!...|                      2|\n",
            "|'816095108013654017'|     Jan 03|         True|             1|            1|@KStefl Sounds li...|                      2|\n",
            "|'816109446069911554'|     Jan 03|         True|             1|            1|@Schoey1992 Happy...|                      2|\n",
            "|'816157517428523008'|     Jan 03|         True|             1|            1|@ratbones666 You ...|                      2|\n",
            "|'816217909819297792'|     Jan 03|         True|             2|            0|@ThorpPerrow Awww...|                      2|\n",
            "|'816314295680110593'|     Jan 03|         True|             2|            0|@thedexterouz Hi!...|                      2|\n",
            "|'816090553595084800'|     Jan 03|         True|             1|            0|@matt_linsley Ple...|                      1|\n",
            "|'816165445925474304'|     Jan 03|         True|             1|            0|@VlSlT Sorry to h...|                      1|\n",
            "|'816323706431668226'|     Jan 03|         True|             1|            0|@PPramod2041984 H...|                      1|\n",
            "|'816190084546498560'|     Jan 03|         True|             1|            0|@mailstosandeep H...|                      1|\n",
            "|'816072943495249921'|     Jan 03|         True|             1|            0|@Elidan_8 Here's ...|                      1|\n",
            "|'816074813408165888'|     Jan 03|         True|             1|            0|@joyfulneesh Than...|                      1|\n",
            "|'816077071801810944'|     Jan 03|         True|             1|            0|@brooklynnnross I...|                      1|\n",
            "|'816086664053456896'|     Jan 03|         True|             1|            0|@DurhamBelle I'm ...|                      1|\n",
            "|'816092970168549376'|     Jan 03|         True|             1|            0|@heypardeep We're...|                      1|\n",
            "|'816093471610195968'|     Jan 03|         True|             1|            0|@__NaijaDrew Sorr...|                      1|\n",
            "|'816203796342833152'|     Jan 03|         True|             1|            0|@magsophazjon Ple...|                      1|\n",
            "|'816204084709654528'|     Jan 03|         True|             1|            0|@magsophazjon Hey...|                      1|\n",
            "+--------------------+-----------+-------------+--------------+-------------+--------------------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4s0OfyGxLi7",
        "colab_type": "code",
        "outputId": "36cb2d5d-f113-42d6-ebd2-2f2b927204b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Selecting column text_ from Task3DataTop100 to perform word count(map-reduce) for the tweets\n",
        "\n",
        "Step3Data_tweets = Step3DataTop100.select(\"text_\").rdd.flatMap(lambda x: x).collect()\n",
        "Step3Data_tweets[0:5]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@amazon worst shopping  experience,  no service, no substantial reply to complaints, no delivery for 1 week post guarantee date.',\n",
              " '@ItsJosshA We always aim to deliver by the date given in your confirmation email. Have we missed that date? Any update in tracking?  ^NF',\n",
              " \"@ItsJosshA Oh no! I'm sorry! Please reach out to us so that we can look into options: https://t.co/hApLpMlfHN. ^JO\",\n",
              " '@KStefl Sounds like you know what to add to your Halloween playlist for this year! ^BV',\n",
              " '@Schoey1992 Happy Birthday, Matt! #FriendsForever #FriendshipGoals ^JO']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGOy2EX8xLAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating Spark Context\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jql9qQ1lxKcd",
        "colab_type": "code",
        "outputId": "b3452e99-ed7b-43d9-c946-b91e51b61d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Reading 'tweet' to a RDD object using spark context\n",
        "tweet_rdd = sc.parallelize(Step3Data_tweets)\n",
        "tweet_rdd.take(5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@amazon worst shopping  experience,  no service, no substantial reply to complaints, no delivery for 1 week post guarantee date.',\n",
              " '@ItsJosshA We always aim to deliver by the date given in your confirmation email. Have we missed that date? Any update in tracking?  ^NF',\n",
              " \"@ItsJosshA Oh no! I'm sorry! Please reach out to us so that we can look into options: https://t.co/hApLpMlfHN. ^JO\",\n",
              " '@KStefl Sounds like you know what to add to your Halloween playlist for this year! ^BV',\n",
              " '@Schoey1992 Happy Birthday, Matt! #FriendsForever #FriendshipGoals ^JO']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr-ulqJ7-N7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b1a52cc-8d24-4893-9004-11bcf1eecafd"
      },
      "source": [
        "type(tweet_rdd)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU4wjTZGFh-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Cleaning text data to count word frequency \n",
        "\n",
        "import string\n",
        "import re\n",
        "\n",
        "def clean_tweet(x):\n",
        "  \n",
        "  # Delete all the URLs in the tweets\n",
        "  text00 = re.sub(r'www\\S+', '', x)\n",
        "  text01 = re.sub(r'http\\S+', '', text00)\n",
        "  \n",
        "  # Delete all the numbers in the tweets\n",
        "  text1 = ''.join([i for i in text01 if not i.isdigit()])\n",
        "  \n",
        "  # Delete all the punctuation marks in the tweets\n",
        "  text2 = text1.translate(str.maketrans('','',string.punctuation))\n",
        "  \n",
        "  # Convert text to LOWERCASE\n",
        "  text3 = text2.lower()\n",
        "\n",
        "  return text3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HgbHCSNFtZB",
        "colab_type": "code",
        "outputId": "e7202c57-239b-41bb-a0ef-0a751ef861f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Cleaning the text of tweets: 1. Removing URLs, 2. Removing non-alphabets, 3. Lowercase \n",
        "clean_tweet_rdd = tweet_rdd.map(clean_tweet)\n",
        "clean_tweet_rdd.take(10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amazon worst shopping  experience  no service no substantial reply to complaints no delivery for  week post guarantee date',\n",
              " 'itsjossha we always aim to deliver by the date given in your confirmation email have we missed that date any update in tracking  nf',\n",
              " 'itsjossha oh no im sorry please reach out to us so that we can look into options  jo',\n",
              " 'kstefl sounds like you know what to add to your halloween playlist for this year bv',\n",
              " 'schoey happy birthday matt friendsforever friendshipgoals jo',\n",
              " 'ratbones you so fancy you already knooow ep',\n",
              " 'thorpperrow a happy birthday you dont look a day over   pass on your details here  for lil surprise rs',\n",
              " 'thedexterouz hi wed like to help when you have a moment please connect with us here   yp',\n",
              " 'mattlinsley please keep us posted on this and let us know if it doesnt arrive tomorrow bv',\n",
              " 'vlslt sorry to hear that contact us here  and well look into it for you as']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yG_0ny2F3FJ",
        "colab_type": "code",
        "outputId": "0042d366-ae7d-4645-9c20-7d6ce761bfd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Building Map function, printing 20 key-value pairs\n",
        "map = clean_tweet_rdd.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1))\n",
        "map.take(20)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('amazon', 1),\n",
              " ('worst', 1),\n",
              " ('shopping', 1),\n",
              " ('', 1),\n",
              " ('experience', 1),\n",
              " ('', 1),\n",
              " ('no', 1),\n",
              " ('service', 1),\n",
              " ('no', 1),\n",
              " ('substantial', 1),\n",
              " ('reply', 1),\n",
              " ('to', 1),\n",
              " ('complaints', 1),\n",
              " ('no', 1),\n",
              " ('delivery', 1),\n",
              " ('for', 1),\n",
              " ('', 1),\n",
              " ('week', 1),\n",
              " ('post', 1),\n",
              " ('guarantee', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKhliGStF6Lb",
        "colab_type": "code",
        "outputId": "f8fc0aec-b981-4f75-9fb9-77adb139a6b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Building Reduce function, printing 20 key-value pairs with word count\n",
        "counts = map.reduceByKey(lambda a, b: a + b)\n",
        "counts.take(20)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('amazon', 7),\n",
              " ('worst', 1),\n",
              " ('', 73),\n",
              " ('no', 5),\n",
              " ('service', 1),\n",
              " ('substantial', 1),\n",
              " ('delivery', 6),\n",
              " ('week', 1),\n",
              " ('itsjossha', 2),\n",
              " ('we', 23),\n",
              " ('always', 3),\n",
              " ('in', 12),\n",
              " ('confirmation', 1),\n",
              " ('have', 18),\n",
              " ('update', 2),\n",
              " ('tracking', 5),\n",
              " ('oh', 1),\n",
              " ('im', 13),\n",
              " ('out', 6),\n",
              " ('us', 28)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrRUVvxpF-zZ",
        "colab_type": "code",
        "outputId": "5b1544a0-9e46-4a8f-a11c-13e4df408571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Total number of distinct words\n",
        "print(len(counts.collect()))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_mwR-KvGKHy",
        "colab_type": "code",
        "outputId": "9e48748a-aa7c-460d-af8d-8e0bb24320b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Task 1 # Step 3\n",
        "# Final word count for all words from 100 tweets\n",
        "countsSorted = counts.takeOrdered(608) # Conditioned on that number of characters in the string should be at least 1\n",
        "countsSorted"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 73),\n",
              " ('a', 25),\n",
              " ('ab', 1),\n",
              " ('abhinavsaroj', 4),\n",
              " ('able', 3),\n",
              " ('about', 4),\n",
              " ('aboutasix', 1),\n",
              " ('above', 2),\n",
              " ('access', 3),\n",
              " ('account', 2),\n",
              " ('accttypically', 1),\n",
              " ('add', 1),\n",
              " ('address', 1),\n",
              " ('adibaddy', 1),\n",
              " ('advise', 1),\n",
              " ('ae', 3),\n",
              " ('af', 2),\n",
              " ('aim', 2),\n",
              " ('ak', 1),\n",
              " ('alerts', 2),\n",
              " ('alexa', 1),\n",
              " ('alexisgraham', 1),\n",
              " ('allow', 1),\n",
              " ('already', 1),\n",
              " ('always', 3),\n",
              " ('alyssagoldman', 3),\n",
              " ('am', 1),\n",
              " ('amazon', 7),\n",
              " ('amazonhelp', 1),\n",
              " ('amazonin', 2),\n",
              " ('ambermullennn', 1),\n",
              " ('amp', 1),\n",
              " ('an', 7),\n",
              " ('and', 17),\n",
              " ('any', 8),\n",
              " ('anything', 1),\n",
              " ('apologies', 2),\n",
              " ('app', 6),\n",
              " ('application', 1),\n",
              " ('appreciation', 1),\n",
              " ('ar', 3),\n",
              " ('are', 2),\n",
              " ('arent', 1),\n",
              " ('ariannadelbene', 1),\n",
              " ('arrange', 1),\n",
              " ('arrive', 6),\n",
              " ('arrived', 3),\n",
              " ('arrives', 1),\n",
              " ('as', 4),\n",
              " ('ask', 1),\n",
              " ('asked', 1),\n",
              " ('assist', 2),\n",
              " ('assistance', 1),\n",
              " ('at', 6),\n",
              " ('athena', 1),\n",
              " ('athenarivera', 1),\n",
              " ('atoz', 1),\n",
              " ('attention', 2),\n",
              " ('availability', 1),\n",
              " ('available', 2),\n",
              " ('aw', 1),\n",
              " ('babajabalpuri', 4),\n",
              " ('back', 1),\n",
              " ('bad', 2),\n",
              " ('baileyoz', 1),\n",
              " ('bayou', 1),\n",
              " ('bbyuniversecb', 1),\n",
              " ('be', 8),\n",
              " ('becoming', 1),\n",
              " ('been', 2),\n",
              " ('being', 1),\n",
              " ('below', 1),\n",
              " ('better', 3),\n",
              " ('bingewatch', 1),\n",
              " ('birthday', 2),\n",
              " ('books', 1),\n",
              " ('bringing', 2),\n",
              " ('brooklynnnross', 1),\n",
              " ('browser', 1),\n",
              " ('business', 2),\n",
              " ('but', 3),\n",
              " ('bv', 2),\n",
              " ('by', 8),\n",
              " ('ca', 1),\n",
              " ('can', 26),\n",
              " ('cancel', 1),\n",
              " ('cant', 2),\n",
              " ('card', 2),\n",
              " ('carriers', 1),\n",
              " ('case', 2),\n",
              " ('caused', 1),\n",
              " ('cd', 1),\n",
              " ('certainly', 1),\n",
              " ('chadrallen', 1),\n",
              " ('chat', 1),\n",
              " ('check', 1),\n",
              " ('checking', 1),\n",
              " ('checkout', 1),\n",
              " ('chunkkyyy', 2),\n",
              " ('cj', 2),\n",
              " ('cl', 2),\n",
              " ('claim', 1),\n",
              " ('cleared', 1),\n",
              " ('click', 1),\n",
              " ('close', 1),\n",
              " ('co', 1),\n",
              " ('cod', 1),\n",
              " ('cold', 1),\n",
              " ('colleagues', 1),\n",
              " ('collection', 1),\n",
              " ('complaints', 1),\n",
              " ('concern', 1),\n",
              " ('concerned', 1),\n",
              " ('concerns', 1),\n",
              " ('confirm', 1),\n",
              " ('confirmation', 1),\n",
              " ('connect', 1),\n",
              " ('connecting', 1),\n",
              " ('contact', 11),\n",
              " ('contacted', 2),\n",
              " ('contacting', 1),\n",
              " ('could', 1),\n",
              " ('couriers', 1),\n",
              " ('crashrider', 1),\n",
              " ('create', 1),\n",
              " ('credit', 1),\n",
              " ('cs', 1),\n",
              " ('ctrl', 1),\n",
              " ('customer', 2),\n",
              " ('customers', 1),\n",
              " ('customs', 1),\n",
              " ('cute', 1),\n",
              " ('cutting', 1),\n",
              " ('damaged', 1),\n",
              " ('danadug', 1),\n",
              " ('danjbalkwill', 1),\n",
              " ('danny', 1),\n",
              " ('darshanhsheth', 3),\n",
              " ('date', 5),\n",
              " ('day', 4),\n",
              " ('days', 1),\n",
              " ('delay', 1),\n",
              " ('delighted', 1),\n",
              " ('deliver', 4),\n",
              " ('delivering', 2),\n",
              " ('delivery', 6),\n",
              " ('department', 2),\n",
              " ('desktop', 1),\n",
              " ('destination', 1),\n",
              " ('details', 6),\n",
              " ('device', 1),\n",
              " ('did', 1),\n",
              " ('didnt', 1),\n",
              " ('direct', 1),\n",
              " ('directly', 1),\n",
              " ('dishanisen', 1),\n",
              " ('dmarie', 1),\n",
              " ('do', 4),\n",
              " ('doesnt', 5),\n",
              " ('dont', 5),\n",
              " ('doug', 1),\n",
              " ('download', 1),\n",
              " ('downloadsr', 1),\n",
              " ('dragonflyeye', 2),\n",
              " ('drop', 1),\n",
              " ('durhambelle', 1),\n",
              " ('earlier', 2),\n",
              " ('earliest', 1),\n",
              " ('edd', 1),\n",
              " ('edit', 1),\n",
              " ('elaborate', 1),\n",
              " ('elidan', 1),\n",
              " ('eligible', 1),\n",
              " ('else', 1),\n",
              " ('email', 5),\n",
              " ('emmawrafter', 1),\n",
              " ('en', 2),\n",
              " ('encourage', 1),\n",
              " ('end', 1),\n",
              " ('enjoying', 2),\n",
              " ('ep', 1),\n",
              " ('error', 1),\n",
              " ('est', 1),\n",
              " ('eumaeusodyssey', 4),\n",
              " ('eval', 1),\n",
              " ('evening', 1),\n",
              " ('exchange', 1),\n",
              " ('expected', 1),\n",
              " ('experience', 9),\n",
              " ('f', 1),\n",
              " ('fancy', 1),\n",
              " ('features', 1),\n",
              " ('feedback', 7),\n",
              " ('feel', 4),\n",
              " ('filled', 1),\n",
              " ('find', 2),\n",
              " ('fitbit', 1),\n",
              " ('flagging', 1),\n",
              " ('following', 2),\n",
              " ('for', 50),\n",
              " ('form', 1),\n",
              " ('forwarded', 1),\n",
              " ('found', 1),\n",
              " ('free', 2),\n",
              " ('friendly', 1),\n",
              " ('friendsforever', 1),\n",
              " ('friendshipgoals', 1),\n",
              " ('from', 2),\n",
              " ('frustrating', 1),\n",
              " ('fulfilled', 1),\n",
              " ('fun', 1),\n",
              " ('further', 5),\n",
              " ('gerzinal', 1),\n",
              " ('get', 3),\n",
              " ('getting', 2),\n",
              " ('ghostfacezach', 1),\n",
              " ('give', 1),\n",
              " ('given', 1),\n",
              " ('gl', 3),\n",
              " ('glad', 3),\n",
              " ('goes', 1),\n",
              " ('great', 2),\n",
              " ('guarantee', 3),\n",
              " ('gxb', 1),\n",
              " ('had', 1),\n",
              " ('halloween', 1),\n",
              " ('happen', 1),\n",
              " ('happy', 5),\n",
              " ('happynewyear', 1),\n",
              " ('has', 3),\n",
              " ('hasnt', 1),\n",
              " ('have', 18),\n",
              " ('hb', 4),\n",
              " ('hear', 4),\n",
              " ('help', 8),\n",
              " ('helped', 1),\n",
              " ('helpep', 1),\n",
              " ('helps', 3),\n",
              " ('here', 32),\n",
              " ('heres', 1),\n",
              " ('hey', 9),\n",
              " ('heypardeep', 1),\n",
              " ('hg', 2),\n",
              " ('hi', 14),\n",
              " ('hk', 1),\n",
              " ('hope', 3),\n",
              " ('how', 3),\n",
              " ('hrs', 1),\n",
              " ('i', 9),\n",
              " ('identify', 1),\n",
              " ('if', 22),\n",
              " ('im', 13),\n",
              " ('improve', 1),\n",
              " ('in', 12),\n",
              " ('inconvenience', 2),\n",
              " ('incorrect', 1),\n",
              " ('indicate', 1),\n",
              " ('indicates', 1),\n",
              " ('info', 4),\n",
              " ('information', 1),\n",
              " ('instances', 1),\n",
              " ('interest', 2),\n",
              " ('internally', 1),\n",
              " ('into', 6),\n",
              " ('investigate', 1),\n",
              " ('is', 13),\n",
              " ('isnt', 2),\n",
              " ('issue', 2),\n",
              " ('issues', 1),\n",
              " ('it', 17),\n",
              " ('item', 5),\n",
              " ('items', 1),\n",
              " ('its', 3),\n",
              " ('itsjossha', 2),\n",
              " ('ive', 1),\n",
              " ('izzyscott', 1),\n",
              " ('ja', 3),\n",
              " ('jaemulaa', 1),\n",
              " ('jeedas', 1),\n",
              " ('jj', 1),\n",
              " ('jo', 6),\n",
              " ('john', 1),\n",
              " ('joke', 1),\n",
              " ('joyfulneesh', 1),\n",
              " ('jrc', 1),\n",
              " ('jtreadway', 1),\n",
              " ('katmcor', 1),\n",
              " ('kd', 1),\n",
              " ('keep', 7),\n",
              " ('keeps', 1),\n",
              " ('kindakuls', 1),\n",
              " ('kindle', 3),\n",
              " ('kindly', 1),\n",
              " ('knooow', 1),\n",
              " ('know', 13),\n",
              " ('knowing', 1),\n",
              " ('kstefl', 1),\n",
              " ('late', 2),\n",
              " ('leave', 3),\n",
              " ('let', 7),\n",
              " ('letting', 2),\n",
              " ('lg', 1),\n",
              " ('li', 1),\n",
              " ('like', 7),\n",
              " ('lil', 1),\n",
              " ('link', 6),\n",
              " ('lisadeee', 1),\n",
              " ('list', 1),\n",
              " ('lizzieejones', 1),\n",
              " ('location', 1),\n",
              " ('longer', 1),\n",
              " ('look', 7),\n",
              " ('looked', 1),\n",
              " ('looking', 2),\n",
              " ('love', 1),\n",
              " ('magsophazjon', 2),\n",
              " ('mailstosandeep', 1),\n",
              " ('make', 2),\n",
              " ('manage', 2),\n",
              " ('mark', 1),\n",
              " ('matt', 1),\n",
              " ('mattlinsley', 1),\n",
              " ('may', 2),\n",
              " ('mcp', 1),\n",
              " ('me', 3),\n",
              " ('media', 1),\n",
              " ('medicine', 1),\n",
              " ('membership', 1),\n",
              " ('menu', 1),\n",
              " ('method', 1),\n",
              " ('missed', 1),\n",
              " ('mm', 1),\n",
              " ('mobile', 1),\n",
              " ('modify', 1),\n",
              " ('moment', 1),\n",
              " ('more', 3),\n",
              " ('most', 3),\n",
              " ('mpos', 1),\n",
              " ('mrpandit', 1),\n",
              " ('much', 2),\n",
              " ('naijadrew', 1),\n",
              " ('need', 4),\n",
              " ('never', 1),\n",
              " ('new', 3),\n",
              " ('newest', 1),\n",
              " ('next', 1),\n",
              " ('nf', 1),\n",
              " ('night', 1),\n",
              " ('no', 5),\n",
              " ('not', 4),\n",
              " ('now', 3),\n",
              " ('number', 1),\n",
              " ('of', 3),\n",
              " ('off', 1),\n",
              " ('oh', 1),\n",
              " ('on', 14),\n",
              " ('online', 1),\n",
              " ('only', 1),\n",
              " ('open', 1),\n",
              " ('options', 3),\n",
              " ('or', 4),\n",
              " ('order', 10),\n",
              " ('orders', 1),\n",
              " ('other', 1),\n",
              " ('our', 10),\n",
              " ('out', 6),\n",
              " ('over', 1),\n",
              " ('packages', 1),\n",
              " ('packaging', 1),\n",
              " ('page', 1),\n",
              " ('pass', 2),\n",
              " ('patience', 1),\n",
              " ('pawansbaish', 2),\n",
              " ('pawsome', 1),\n",
              " ('payment', 2),\n",
              " ('phone', 2),\n",
              " ('phonechat', 1),\n",
              " ('picture', 1),\n",
              " ('pk', 1),\n",
              " ('place', 1),\n",
              " ('plainbananas', 1),\n",
              " ('playlist', 1),\n",
              " ('please', 20),\n",
              " ('pls', 3),\n",
              " ('pm', 1),\n",
              " ('post', 1),\n",
              " ('posted', 6),\n",
              " ('ppramod', 1),\n",
              " ('pretty', 1),\n",
              " ('prime', 1),\n",
              " ('process', 1),\n",
              " ('product', 1),\n",
              " ('profgambs', 1),\n",
              " ('promised', 1),\n",
              " ('provided', 3),\n",
              " ('puppy', 1),\n",
              " ('purchased', 1),\n",
              " ('put', 1),\n",
              " ('qualify', 1),\n",
              " ('quality', 1),\n",
              " ('queenattallah', 1),\n",
              " ('questions', 2),\n",
              " ('quickly', 1),\n",
              " ('ra', 1),\n",
              " ('ratbones', 1),\n",
              " ('rather', 2),\n",
              " ('reach', 3),\n",
              " ('reading', 1),\n",
              " ('real', 1),\n",
              " ('receive', 1),\n",
              " ('received', 1),\n",
              " ('receiver', 1),\n",
              " ('recent', 1),\n",
              " ('recommend', 1),\n",
              " ('redeeming', 1),\n",
              " ('refund', 2),\n",
              " ('refunds', 1),\n",
              " ('regarding', 1),\n",
              " ('regret', 1),\n",
              " ('relevant', 1),\n",
              " ('repeated', 1),\n",
              " ('replacement', 1),\n",
              " ('replacements', 1),\n",
              " ('reply', 2),\n",
              " ('report', 2),\n",
              " ('reported', 1),\n",
              " ('request', 4),\n",
              " ('requested', 2),\n",
              " ('resolved', 1),\n",
              " ('return', 3),\n",
              " ('returnexchange', 1),\n",
              " ('returnreplacement', 1),\n",
              " ('returns', 1),\n",
              " ('review', 4),\n",
              " ('reviewed', 1),\n",
              " ('reviews', 1),\n",
              " ('right', 1),\n",
              " ('rm', 1),\n",
              " ('rockerdharm', 1),\n",
              " ('ronaldorlemes', 1),\n",
              " ('roxsi', 1),\n",
              " ('rs', 2),\n",
              " ('rw', 1),\n",
              " ('rwwishart', 1),\n",
              " ('saififiroz', 2),\n",
              " ('same', 1),\n",
              " ('sb', 1),\n",
              " ('scan', 3),\n",
              " ('schoey', 1),\n",
              " ('see', 3),\n",
              " ('seeing', 1),\n",
              " ('seentitties', 1),\n",
              " ('select', 1),\n",
              " ('seller', 5),\n",
              " ('send', 1),\n",
              " ('sent', 1),\n",
              " ('separate', 1),\n",
              " ('service', 1),\n",
              " ('settings', 1),\n",
              " ('sgtwinters', 1),\n",
              " ('sh', 6),\n",
              " ('shall', 1),\n",
              " ('share', 1),\n",
              " ('shared', 1),\n",
              " ('sharing', 1),\n",
              " ('sharrypigtails', 1),\n",
              " ('ship', 1),\n",
              " ('shipment', 1),\n",
              " ('shirt', 1),\n",
              " ('shopping', 3),\n",
              " ('shoppingsr', 1),\n",
              " ('should', 2),\n",
              " ('shout', 1),\n",
              " ('shoutout', 1),\n",
              " ('showing', 1),\n",
              " ('site', 3),\n",
              " ('sj', 6),\n",
              " ('sjbooktweeter', 2),\n",
              " ('so', 18),\n",
              " ('social', 1),\n",
              " ('some', 2),\n",
              " ('soon', 2),\n",
              " ('sorry', 21),\n",
              " ('sorted', 2),\n",
              " ('sound', 1),\n",
              " ('sounds', 1),\n",
              " ('speak', 1),\n",
              " ('specific', 1),\n",
              " ('spotify', 1),\n",
              " ('sr', 3),\n",
              " ('stadesse', 1),\n",
              " ('start', 1),\n",
              " ('status', 2),\n",
              " ('stay', 1),\n",
              " ('stayhealthy', 1),\n",
              " ('steps', 4),\n",
              " ('still', 1),\n",
              " ('stock', 2),\n",
              " ('stopped', 1),\n",
              " ('submit', 1),\n",
              " ('substantial', 1),\n",
              " ('supervisor', 1),\n",
              " ('support', 3),\n",
              " ('sure', 4),\n",
              " ('surprise', 1),\n",
              " ('sydneycohenour', 1),\n",
              " ('tamarastampone', 1),\n",
              " ('td', 1),\n",
              " ('team', 2),\n",
              " ('teams', 2),\n",
              " ('text', 1),\n",
              " ('than', 1),\n",
              " ('thank', 1),\n",
              " ('thanks', 11),\n",
              " ('that', 18),\n",
              " ('thats', 2),\n",
              " ('thblomme', 1),\n",
              " ('the', 65),\n",
              " ('thedexterouz', 1),\n",
              " ('them', 1),\n",
              " ('then', 3),\n",
              " ('there', 2),\n",
              " ('these', 4),\n",
              " ('they', 1),\n",
              " ('things', 1),\n",
              " ('thirdparty', 2),\n",
              " ('this', 27),\n",
              " ('thorpperrow', 1),\n",
              " ('through', 3),\n",
              " ('time', 3),\n",
              " ('tm', 2),\n",
              " ('to', 64),\n",
              " ('tomorrow', 2),\n",
              " ('tomroe', 1),\n",
              " ('tracking', 5),\n",
              " ('transit', 1),\n",
              " ('tried', 1),\n",
              " ('trouble', 3),\n",
              " ('truly', 2),\n",
              " ('try', 3),\n",
              " ('trying', 1),\n",
              " ('tuned', 1),\n",
              " ('twitter', 2),\n",
              " ('typically', 2),\n",
              " ('unable', 2),\n",
              " ('understand', 1),\n",
              " ('unlinkinglinking', 1),\n",
              " ('until', 2),\n",
              " ('uoduckscotty', 1),\n",
              " ('up', 2),\n",
              " ('update', 2),\n",
              " ('updated', 1),\n",
              " ('updates', 3),\n",
              " ('upride', 1),\n",
              " ('us', 28),\n",
              " ('use', 1),\n",
              " ('using', 2),\n",
              " ('very', 1),\n",
              " ('via', 4),\n",
              " ('vickyfilmydev', 1),\n",
              " ('video', 2),\n",
              " ('view', 1),\n",
              " ('visit', 2),\n",
              " ('vlslt', 1),\n",
              " ('vs', 1),\n",
              " ('waiting', 1),\n",
              " ('wan', 1),\n",
              " ('want', 2),\n",
              " ('was', 5),\n",
              " ('way', 2),\n",
              " ('we', 23),\n",
              " ('website', 1),\n",
              " ('wed', 5),\n",
              " ('week', 1),\n",
              " ('well', 9),\n",
              " ('went', 1),\n",
              " ('were', 9),\n",
              " ('weve', 1),\n",
              " ('what', 5),\n",
              " ('whats', 1),\n",
              " ('when', 5),\n",
              " ('where', 2),\n",
              " ('which', 1),\n",
              " ('while', 2),\n",
              " ('will', 6),\n",
              " ('windows', 1),\n",
              " ('with', 6),\n",
              " ('within', 1),\n",
              " ('wj', 4),\n",
              " ('work', 1),\n",
              " ('working', 1),\n",
              " ('worst', 1),\n",
              " ('written', 1),\n",
              " ('wrong', 2),\n",
              " ('wyour', 1),\n",
              " ('year', 2),\n",
              " ('you', 60),\n",
              " ('youd', 2),\n",
              " ('your', 33),\n",
              " ('youre', 2),\n",
              " ('yourself', 1),\n",
              " ('yp', 2),\n",
              " ('zesaiyan', 1),\n",
              " ('\\u200bhey', 1),\n",
              " ('😊', 1),\n",
              " ('😌', 1),\n",
              " ('😷😷', 1),\n",
              " ('🙋', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI8KX2x0G1y2",
        "colab_type": "code",
        "outputId": "36aa28bc-0465-4152-c87a-eda3378f325a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "## Converting the final Map-reduce output into a pandas data frame\n",
        "import pandas as pd\n",
        "\n",
        "MapReduceOutput = pd.DataFrame(countsSorted, columns = ['Tweet_Word' , \"Frequency\"])\n",
        "print(MapReduceOutput)\n",
        "MapReduceOutput.head()\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Tweet_Word  Frequency\n",
            "0                         73\n",
            "1               a         25\n",
            "2              ab          1\n",
            "3    abhinavsaroj          4\n",
            "4            able          3\n",
            "..            ...        ...\n",
            "603          ​hey          1\n",
            "604             😊          1\n",
            "605             😌          1\n",
            "606            😷😷          1\n",
            "607             🙋          1\n",
            "\n",
            "[608 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_Word</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ab</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abhinavsaroj</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>able</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Tweet_Word  Frequency\n",
              "0                       73\n",
              "1             a         25\n",
              "2            ab          1\n",
              "3  abhinavsaroj          4\n",
              "4          able          3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEI-PVf7Hy3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exporting output of Map-Reduce output to an excel file\n",
        "\n",
        "MapReduceOutput.to_excel(r\"C:\\Users\\saksh\\UIC 2020 Spring\\Analytics for big data\\HW2\\Ass2_Mapreduce.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwc8u8WsTgYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 2\n",
        "# Renaming id_str column to tweet_id in Tweet_sdf - our original Amazon_Responded_Oct05.csv Spark dataframe(before filtering operations) \n",
        "\n",
        "Tweet_sdf = Tweet_sdf.withColumnRenamed(\"id_str\", \"tweet_id\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6b7mlU5IzyX",
        "colab_type": "code",
        "outputId": "4b5da1a7-88b3-4dc9-a0cf-62773b686246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Task 2\n",
        "#Importing the find_text data as a pandas dataframe and printing its shape\n",
        "\n",
        "import pandas as pd\n",
        "find_text = pd.read_csv(\"/content/find_text.csv\") \n",
        "find_text.head()\n",
        "find_text.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53928, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrVRfFbxJO03",
        "colab_type": "code",
        "outputId": "402bbda5-4452-428a-c309-915699de00d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Task 2\n",
        "# Converting find_text Pandas Dataframe into Spark RDD Dataframe and printing 10 rows\n",
        "\n",
        "find_text = find_text.astype(str) # Converting pandas df to string first\n",
        "find_text_sdf = spark.createDataFrame(find_text)\n",
        "find_text_sdf.show(10, False) # False allows us to show entire content of the columns"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+\n",
            "|id_str              |text|\n",
            "+--------------------+----+\n",
            "|'793270689780203520'|nan |\n",
            "|'793281386912354304'|nan |\n",
            "|'793299404975247360'|nan |\n",
            "|'793301295255945216'|nan |\n",
            "|'793315815411978240'|nan |\n",
            "|'793322306848292864'|nan |\n",
            "|'793322433625415680'|nan |\n",
            "|'793365409047023616'|nan |\n",
            "|'793369654878232577'|nan |\n",
            "|'793375905280393216'|nan |\n",
            "+--------------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdr_yLSaLLf8",
        "colab_type": "code",
        "outputId": "cbe8ef3a-a603-4200-8bb6-0d8592ec1793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "# Task 2\n",
        "# Applying Left join on find_text_sdf with Tweet_sdf as id_str as our key\n",
        "\n",
        "left_join = find_text_sdf.join(Tweet_sdf, find_text_sdf.id_str == Tweet_sdf.tweet_id, how='left') # Could also use 'left_outer'\n",
        "left_join.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+--------------------+--------------------+----------------+-----------+-------------------+---------------------+--------------+-----------------+--------------+--------------------+--------------------+-------------+--------------------+------------------+--------------------+--------------+--------------------+--------------+---------+-----------------------+-------------------------+-----------------------+-------------+---------+--------------------+-------+-----+----+---------+-----+----+-----------+\n",
            "|              id_str|text|            tweet_id|    tweet_created_at|user_screen_name|user_id_str|user_statuses_count|user_favourites_count|user_protected|user_listed_count|user_following|    user_description|       user_location|user_verified|user_followers_count|user_friends_count|     user_created_at|tweet_language|               text_|favorite_count|favorited|in_reply_to_screen_name|in_reply_to_status_id_str|in_reply_to_user_id_str|retweet_count|retweeted|                text|WeekDay|Month|Date|TimeStamp|  Geo|Year|Create_Date|\n",
            "+--------------------+----+--------------------+--------------------+----------------+-----------+-------------------+---------------------+--------------+-----------------+--------------+--------------------+--------------------+-------------+--------------------+------------------+--------------------+--------------+--------------------+--------------+---------+-----------------------+-------------------------+-----------------------+-------------+---------+--------------------+-------+-----+----+---------+-----+----+-----------+\n",
            "|'793322306848292864'| nan|'793322306848292864'|Tue Nov 01 05:22:...|      AmazonHelp| 85741735.0|          2225478.0|              11366.0|         False|            792.0|         False|We answer Amazon ...|                 nan|         True|            149571.0|              53.0|Wed Oct 28 04:17:...|            en|@Murtazansp Hello...|           0.0|    False|             Murtazansp|                 7.93e+17|           2908108256.0|          0.0|    False|                 nan|    Tue|  Nov|  01| 05:22:31|+0000|2016|     Nov 01|\n",
            "|'802611169642983424'| nan|'802611169642983424'|Sat Nov 26 20:33:...|     AsherzMason|715293713.0|            27157.0|              33195.0|         False|             44.0|         False|             22 🇬🇧|                 nan|        False|               553.0|             166.0|Mon Oct 14 23:37:...|            en|@AmazonHelp Can't...|           0.0|    False|             AmazonHelp|                 8.03e+17|             85741735.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:33:09|+0000|2016|     Nov 26|\n",
            "|'802612367855157249'| nan|'802612367855157249'|Sat Nov 26 20:37:...|      AmazonHelp| 85741735.0|          2226902.0|              11379.0|         False|            794.0|         False|We answer Amazon ...|                 nan|         True|            149675.0|              53.0|Wed Oct 28 04:17:...|            en|@uglybeautyqueen ...|           0.0|    False|        uglybeautyqueen|                 8.03e+17|             35028391.0|          0.0|    False|@uglybeautyqueen ...|    Sat|  Nov|  26| 20:37:54|+0000|2016|     Nov 26|\n",
            "|'802610799613243392'| nan|'802610799613243392'|Sat Nov 26 20:31:...|  HeLovedGlitter|354190845.0|            47498.0|               2694.0|         False|             11.0|         False|En el Amor con Mi...|            ✨✨✨✨✨✨✨✨|        False|               512.0|             619.0|Sat Aug 13 08:43:...|            en|@AmazonHelp so tr...|           0.0|    False|             AmazonHelp|                 8.03e+17|             85741735.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:31:41|+0000|2016|     Nov 26|\n",
            "|'802612493830987776'| nan|'802612493830987776'|Sat Nov 26 20:38:...|      missygpnyc| 19739759.0|            17416.0|               5635.0|         False|              6.0|         False|Lewisham Girl, Yo...|                 nan|        False|               207.0|             655.0|Thu Jan 29 22:41:...|            en|@AmazonHelp For n...|           0.0|    False|             AmazonHelp|                 8.03e+17|             85741735.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:38:25|+0000|2016|     Nov 26|\n",
            "|'793378188416131072'| nan|'793378188416131072'|Tue Nov 01 09:04:...|      AmazonHelp| 85741735.0|          2225496.0|              11366.0|         False|            792.0|         False|We answer Amazon ...|                 nan|         True|            149570.0|              53.0|Wed Oct 28 04:17:...|            en|@imkapsicum about...|           0.0|    False|             imkapsicum|                 7.93e+17|             59156981.0|          0.0|    False|                 nan|    Tue|  Nov|  01| 09:04:35|+0000|2016|     Nov 01|\n",
            "|'802612002329858049'| nan|'802612002329858049'|Sat Nov 26 20:36:...|      AmazonHelp| 85741735.0|          2226902.0|              11379.0|         False|            794.0|         False|We answer Amazon ...|                 nan|         True|            149675.0|              53.0|Wed Oct 28 04:17:...|            en|@faizanams Hi, so...|           0.0|    False|              faizanams|                 8.03e+17|            837127824.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:36:27|+0000|2016|     Nov 26|\n",
            "|'802611248890265604'| nan|'802611248890265604'|Sat Nov 26 20:33:...|      AmazonHelp| 85741735.0|          2226916.0|              11379.0|         False|            794.0|         False|We answer Amazon ...|                 nan|         True|            149676.0|              53.0|Wed Oct 28 04:17:...|            en|@mvel4u Sorry to ...|           0.0|    False|                 mvel4u|                 8.03e+17|            432582372.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:33:28|+0000|2016|     Nov 26|\n",
            "|'802611458504847360'| nan|'802611458504847360'|Sat Nov 26 20:34:...| uglybeautyqueen| 35028391.0|             2267.0|                120.0|         False|              3.0|         False|I love my kids , ...|          Sheffield |        False|               134.0|             157.0|Fri Apr 24 20:23:...|            en|@AmazonUK What ti...|           0.0|    False|               AmazonUK|                      nan|            209004862.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:34:18|+0000|2016|     Nov 26|\n",
            "|'793393912769576960'| nan|'793393912769576960'|Tue Nov 01 10:07:...|     mybharatraj|902137872.0|             1248.0|                293.0|         False|              2.0|         False|         Mera BHARAT|               India|        False|                50.0|              13.0|Wed Oct 24 16:24:...|            en|@AmazonHelp now a...|           0.0|    False|            mybharatraj|                 7.93e+17|            902137872.0|          0.0|    False|                 nan|    Tue|  Nov|  01| 10:07:04|+0000|2016|     Nov 01|\n",
            "|'793369654878232577'| nan|'793369654878232577'|Tue Nov 01 08:30:...|      imkapsicum| 59156981.0|              257.0|                 89.0|         False|              0.0|         False|Web-developer, up...|       Mumbai, India|        False|                94.0|              58.0|Wed Jul 22 15:36:...|            en|xtremely annoyed ...|           0.0|    False|                    nan|                      nan|                    nan|          0.0|    False|                 nan|    Tue|  Nov|  01| 08:30:40|+0000|2016|     Nov 01|\n",
            "|'802611490289291264'| nan|'802611490289291264'|Sat Nov 26 20:34:...|      AmazonHelp| 85741735.0|          2226916.0|              11379.0|         False|            794.0|         False|We answer Amazon ...|                 nan|         True|            149676.0|              53.0|Wed Oct 28 04:17:...|            en|@mvel4u Please do...|           0.0|    False|                 mvel4u|                 8.03e+17|            432582372.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:34:25|+0000|2016|     Nov 26|\n",
            "|'802610828373594115'| nan|'802610828373594115'|Sat Nov 26 20:31:...|       jackiesic| 37080099.0|            42252.0|               1224.0|         False|            167.0|         False|Fiscal Conservati...|Southeast of Diso...|        False|              6047.0|            5187.0|Fri May 01 23:50:...|            en|@AmazonHelp On ch...|           0.0|    False|             AmazonHelp|                 8.03e+17|             85741735.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:31:47|+0000|2016|     Nov 26|\n",
            "|'793382930085253121'| nan|'793382930085253121'|Tue Nov 01 09:23:...|      AmazonHelp| 85741735.0|          2225534.0|              11367.0|         False|            795.0|         False|We answer Amazon ...|                 nan|         True|            149573.0|              53.0|Wed Oct 28 04:17:...|            en|@mybharatraj Hi! ...|           0.0|    False|            mybharatraj|                 7.93e+17|            902137872.0|          0.0|    False|@mybharatraj Hi! ...|    Tue|  Nov|  01| 09:23:25|+0000|2016|     Nov 01|\n",
            "|'793379112685568000'| nan|'793379112685568000'|Tue Nov 01 09:08:...|     mybharatraj|902137872.0|             1248.0|                293.0|         False|              2.0|         False|         Mera BHARAT|               India|        False|                50.0|              13.0|Wed Oct 24 16:24:...|            en|@amazonIN it is r...|           0.0|    False|               amazonIN|                      nan|           1282946089.0|          0.0|    False|                 nan|    Tue|  Nov|  01| 09:08:15|+0000|2016|     Nov 01|\n",
            "|'802611878274809856'| nan|'802611878274809856'|Sat Nov 26 20:35:...|      christesla|174427901.0|             5793.0|               2114.0|         False|             32.0|         False|Director of @Cybe...|           Liverpool|        False|               702.0|             918.0|Tue Aug 03 22:26:...|            en|@AmazonUK what ti...|           0.0|    False|               AmazonUK|                      nan|            209004862.0|          0.0|    False|@AmazonUK what ti...|    Sat|  Nov|  26| 20:35:58|+0000|2016|     Nov 26|\n",
            "|'802611248424751104'| nan|'802611248424751104'|Sat Nov 26 20:33:...|      AmazonHelp| 85741735.0|          2226916.0|              11379.0|         False|            794.0|         False|We answer Amazon ...|                 nan|         True|            149676.0|              53.0|Wed Oct 28 04:17:...|            en|@Jonny_Winter I'm...|           0.0|    False|           Jonny_Winter|                 8.03e+17|             90684338.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:33:28|+0000|2016|     Nov 26|\n",
            "|'802611489521733632'| nan|'802611489521733632'|Sat Nov 26 20:34:...|      AmazonHelp| 85741735.0|          2226916.0|              11379.0|         False|            794.0|         False|We answer Amazon ...|                 nan|         True|            149676.0|              53.0|Wed Oct 28 04:17:...|            en|@mvel4u Request y...|           0.0|    False|                 mvel4u|                 8.03e+17|            432582372.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:34:25|+0000|2016|     Nov 26|\n",
            "|'802611347338850304'| nan|'802611347338850304'|Sat Nov 26 20:33:...|        HoopRobe|628477747.0|             8265.0|               2200.0|         False|              0.0|         False|views are not my ...|Vancouver, Britis...|        False|               193.0|             154.0|Fri Jul 06 15:29:...|            en|@AmazonHelp 'Amaz...|           0.0|    False|             AmazonHelp|                 8.03e+17|             85741735.0|          0.0|    False|                 nan|    Sat|  Nov|  26| 20:33:51|+0000|2016|     Nov 26|\n",
            "|'793381418395136000'| nan|'793381418395136000'|Tue Nov 01 09:17:...| praveen_pandey_|110354554.0|              408.0|                  3.0|         False|              1.0|         False|                 nan|                 nan|        False|                52.0|              37.0|Mon Feb 01 07:21:...|            en|@AmazonHelp yster...|           0.0|    False|             AmazonHelp|                      nan|             85741735.0|          0.0|    False|                 nan|    Tue|  Nov|  01| 09:17:25|+0000|2016|     Nov 01|\n",
            "+--------------------+----+--------------------+--------------------+----------------+-----------+-------------------+---------------------+--------------+-----------------+--------------+--------------------+--------------------+-------------+--------------------+------------------+--------------------+--------------+--------------------+--------------+---------+-----------------------+-------------------------+-----------------------+-------------+---------+--------------------+-------+-----+----+---------+-----+----+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzSCD2sqSgjN",
        "colab_type": "code",
        "outputId": "6be6684c-6c5e-4649-fd23-cd0ce826c959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# making sure the number of rows in joined dataframe is same as the original find_text dataframe\n",
        "left_join.count()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-a0DTEgZQHD",
        "colab_type": "code",
        "outputId": "10b56828-820c-4d6b-d849-f5fab83c3b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "# Task 2\n",
        "# Selecting id_str and text_ from the joined Dataframe left_join\n",
        "\n",
        "left_join_out = left_join.select(left_join.id_str, left_join.text_)\n",
        "left_join_out.show(20, False)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|id_str              |text_                                                                                                                                                     |\n",
            "+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|'793552243689676800'|@AmazonHelp amazon have made and admitted to a series of error that have impacted a myself and a colleague                                                |\n",
            "|'793595479116439552'|@SuNoSuKo Please don't provide your order details we consider them as personal info. Our twitter page is visible to public. ^VM                           |\n",
            "|'793751757247619072'|@aasifkhan Hey, I'm sorry for this. Product should reach the fulfillment center, when it does the refund will be issued. ^AA                              |\n",
            "|'793788930361556996'|@AmazonHelp I would get more assistance from the dead than from AmazonUK                                                                                  |\n",
            "|'793797330310983680'|Disgusting service @amazonIN\r\n",
            "Products are not getting delivered at door step instead getting call from delivery boy to collect from bus stop             |\n",
            "|'793819060505108480'|@Joe_Twells1 Sorry about that! Please try this Contact Us link for the UK: https://t.co/qy3J24VGxb. ^LS                                                   |\n",
            "|'793828605746896897'|Made an order using @AmazonUK Prime last Wednesday. Waited in for it all day Saturday as it was 'being delivered today'. It's just arrived 😑             |\n",
            "|'793899985444241408'|@JohnnyHeatrock Hey, thanks for reaching out. You should find some helpful information about this offer here: https://t.co/hb0WbW7w9l ^PF                 |\n",
            "|'793903133462331392'|@mrniceguy1987 Please keep us posted with the arrival of your order. We want to make sure it gets to you. ^GL                                             |\n",
            "|'793904094595444736'|@AmazonHelp will do                                                                                                                                       |\n",
            "|'793920564628955137'|@AmazonHelp need help with fire stick. There's nothing on network settings. Tried to call but users on phone useless https://t.co/x72TzjatGj              |\n",
            "|'793923389203316736'|@magicwaz Sorry for the delays. Have you received any emails recently explaining the extensions? ^BG                                                      |\n",
            "|'794220779768451072'|@AmazonHelp I could see it is available from the same seller, yet i am being denied for a replacement. \r\n",
            "myphone : +91-7899888859. https://t.co/UQj7S9AEYg|\n",
            "|'794263348447678464'|@Nikki_Revak I'm sorry your FireTV Stick isn't working.Can you tell us what's happening? Have you restarted it: https://t.co/8hGwd2KfmD? ^KD              |\n",
            "|'794279214388285440'|@samthejewishguy Sorry to hear this! You can find refund/replacement options here:  https://t.co/Y5jpI9gRhE. ^MT                                          |\n",
            "|'794280604221276160'|@jesskatopps Sorry for this. For help on how to change the language please look here: https://t.co/cha8S78HwI ^GE                                         |\n",
            "|'794305189926858753'|@AmazonHelp my package was supposed to arrive tomorrow, but now it's set back until the 9th . Very frustrating.                                           |\n",
            "|'794314585608167425'|@KrishnaNand162 Hi, I'm afraid we'll not be able to provide any further insight with your concern. 1/2 ^MJ                                                |\n",
            "|'794565369084186625'|@shiv_iipm Please don't provide your details, as we consider it to be personal information. Our Twitter page is visible to the public. ^AM                |\n",
            "|'794648919720493061'|@_Balaji_ Hi there, for us to assist you better please reach us via https://t.co/4hcVq1YXsB &gt; Select the issue &gt; choose phone &gt; (1/2)            |\n",
            "+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W19RMaDgZLmE",
        "colab_type": "code",
        "outputId": "6323a1a9-f7e0-47bc-c515-5f4eaa6496c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# Converting the Spark dataframe into pandas\n",
        "\n",
        "join_output = left_join_out.select(\"*\").toPandas()\n",
        "print(join_output)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     id_str                                              text_\n",
            "0      '793552243689676800'  @AmazonHelp amazon have made and admitted to a...\n",
            "1      '793595479116439552'  @SuNoSuKo Please don't provide your order deta...\n",
            "2      '793751757247619072'  @aasifkhan Hey, I'm sorry for this. Product sh...\n",
            "3      '793788930361556996'  @AmazonHelp I would get more assistance from t...\n",
            "4      '793797330310983680'  Disgusting service @amazonIN\\r\\nProducts are n...\n",
            "...                     ...                                                ...\n",
            "53923  '809401768211685376'  @AmazonVideoIN Censored content, no support fo...\n",
            "53924  '809412394212466689'  @AmazonHelp @rathipoonam please share details,...\n",
            "53925  '809449404801421314'  @SlapdashGourmet We'd like to help. Are all it...\n",
            "53926  '809513226144804864'  @deecaltee When did you reach out to the selle...\n",
            "53927  '809729921320882179'  @engeetham Hi, sorry for the long stretch. We'...\n",
            "\n",
            "[53928 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlfqY7A3Y6Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Exporting the find_text output with id_str and tweet text into an excel file\n",
        "join_output.to_excel(r\"C:\\Users\\saksh\\UIC 2020 Spring\\Analytics for big data\\HW2\\find_text_output.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}